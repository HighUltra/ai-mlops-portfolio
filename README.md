# AI / MLOps Portfolio

**Objetivo:** Convertirme en AI Engineer / MLOps Engineer mediante proyectos end-to-end con despliegue real, monitoreo y documentaci√≥n profesional.

**Estado actual:** Fase 1 ‚Äì Fundamentos de Python para datos y ML.

---
## Estructura del Proyecto
* **00_setup:** Configuraci√≥n del entorno, Docker y herramientas.
* **01_python_data:** Notebooks de pr√°ctica con Pandas y NumPy.
* **datasets:** Archivos de datos locales para experimentos.
---
## Progreso del Proyecto
- [x] **Fase 0:** Setup del entorno (Python, Conda, Docker).
- [x] **Fase 1:** Fundamentos de Python para Datos.
                - [x] 1.3 Transformaciones y agregaciones.
                  - ##Insights: 1. Los clientes que abandonan la empresa (Churn) llaman en promedio 2.2 veces a soporte, comparado con 1.4 veces de los clientes  leales.
                  - 2. El gasto promedio de los clientes que se van es mayor ($65 vs $58).
                
                - [x] 1.4 Operaciones avanzadas y automatizaci√≥n (Script ETL)
                  - Implementaci√≥n de `scripts/etl.py` para procesamiento por l√≠nea de comandos.
                  - Uso de operaciones vectorizadas para optimizar el rendimiento.
        
        - Habilidades T√©cnicas Demostradas:
        
        - Limpieza de datos con Pandas.
        - Automatizaci√≥n mediante scripts ETL.
        - An√°lisis de bases de datos relacionales con SQLite y SQL Avanzado.

- [x] Fase 1.6: Machine Learning Baseline.
    - Implementaci√≥n de `Random Forest` con balanceo de clases.
    - M√©tricas obtenidas: **95% Accuracy** y **78.2% F1-Score** (promedio en CrossValidation/ CV).
    - Exportaci√≥n de artefactos: Modelo y Escalador guardados en `/models` para despliegue.

  - ### üìà Comparativa de Modelos
  - 
En esta fase evaluamos dos aproximaciones para establecer nuestra l√≠nea base (baseline):

| Modelo |                 Accuracy | Recall (Clase: Fuga) | F1-Score | Notas                                          |
 **Logistic Regression** | 86%      | 21%                  | 31%      | Muy d√©bil detectando fugas reales.             |
 **Random Forest**       | **95%**  | **67%**              | **80%**  | **Modelo elegido.** Alta precisi√≥n y robustez. |

> **Insight:** El cambio a Random Forest junto con el balanceo de clases permiti√≥ triplicar la capacidad del modelo para identificar clientes en riesgo de abandono comparado con el anterior modelo utilizado de regresion logistica.

> ### üîß Fase 1.6.1: Optimizaci√≥n de Hyperpar√°metros
Se utiliz√≥ `GridSearchCV` para encontrar la configuraci√≥n √≥ptima del bosque, logrando reducir el sobreajuste (overfitting).

- **Mejor Configuraci√≥n:** `max_depth: 10`, `n_estimators: 200`.
- **Resultado Final (F1-Score):** **83.71%** (Mejora del ~5% sobre el baseline).
- **Estado:** Modelo listo para la fase de MLOps y Despliegue.
- 
- [x] **Fase 1.7: Automatizaci√≥n y Cierre de Fase**
    - [x] Creaci√≥n de `scripts/run_train.py` para entrenamiento reproducible.
    - [x] Implementaci√≥n de **SMOTE** para balanceo de clases.
    - [x] Generaci√≥n de `requirements.txt` para portabilidad.
    - [x] **M√©trica Final:** F1-Score del **82%** (Logrando un Recall del 83% en fugas).
    - [x] Artefactos exportados: `model_v1.joblib` y `scaler_v1.joblib`.

- [x] **Fase 2: Transformers Intro**
    - Implementaci√≥n de Pipeline de Sentimiento con `distilbert-base-uncased`.
    - Tiempo de inferencia detectado: **~0.039s** (Inferencia en CPU).
    - Pruebas exitosas detectando polaridad en frases de prueba.

- [x] **Fase 2.3: Embeddings y Almacenamiento**
    - Generaci√≥n de embeddings densos (384 dimensiones) usando `all-MiniLM-L6-v2`.
    - Procesamiento de un lote de 100 documentos sint√©ticos de quejas de clientes.
    - Almacenamiento persistente de vectores en formato `.npy` y metadatos en `.parquet`.

- [x] **Fase 2.4: Vector Database (ChromaDB)**
    - Implementaci√≥n de base de datos vectorial local con **ChromaDB**.
    - Indexaci√≥n exitosa de 100 vectores con sus respectivos IDs y documentos.
    - **M√©trica de Latencia de B√∫squeda:** **0.045s** (B√∫squeda sem√°ntica top-3).
    - Capacidad de recuperaci√≥n demostrada: El sistema identifica "internet speed" como concepto relacionado a "slow connection". 
  
- [x] **Fase 2.5: RAG Simple (Pipeline Completo)**
    - Implementaci√≥n de arquitectura **Retrieval-Augmented Generation**.
    - Integraci√≥n de **ChromaDB** como recuperador de contexto y **Flan-T5** como generador de respuestas.
    - Creaci√≥n de `scripts/rag_service.py`: Un servicio modular y portable que utiliza rutas absolutas para mayor robustez.
    - **Resultado:** El sistema es capaz de responder preguntas sobre problemas t√©cnicos bas√°ndose exclusivamente en el contexto recuperado (evitando alucinaciones b√°sicas).

---
## üõ†Ô∏è Tecnolog√≠as Fase 2
* **Modelos:** `sentence-transformers` (Embeddings), `Flan-T5-Small` (Generaci√≥n).
* **Vector DB:** ChromaDB (Local Persistence).
* **L√≥gica:** Python orientado a objetos para el servicio RAG.
              